{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa368d9-75a8-4b9f-96e7-56361b91faa6",
   "metadata": {},
   "source": [
    "### AI  > ML > Deep Learning > Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e63f11-c810-43d5-97f3-c4e0b8a7f786",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "source": [
    "# ANN\n",
    "## Str of Neural Network (ANN)\n",
    "### 3 Layers =>\n",
    "- Input Layer : Data inputed to NN; Each Circle represents one feature (a piece of info); Circles mean's variables / data set fed into it\n",
    "- Hidden layer 1 & 2 : processing\n",
    "- Output layer : Result\n",
    "* Perceptron : No Hidden layer; Direct from input to Output ; Linear classifier; has many limitations \n",
    " \n",
    "#### Comparison with Neuron :-\n",
    "* Dendrite : refers to input \n",
    "* Axon : output delivered thru axon\n",
    "    - width of dendrites define the weight associated with it\n",
    " \n",
    "### ANN\n",
    "- X1, X2 .... <= Input Layer\n",
    "- Y1, Y2, ... <= Output Layer\n",
    "-  S =  Î£ X<sub>i</sub> W<sub>i</sub>\n",
    "    - combinaions of X and W based on path for each prticular layer\n",
    "- Hidden Layer : H1, H2, ...\n",
    "- Wi <==> Weights  \n",
    "- Bias  : less than 1; B1, B2, ...\n",
    "- Activation with sigmoid fn => The output for a single layer (process of forward propagation)\n",
    "- Z ==> S + bias\n",
    "- Sigmoid Fn : $$ x = {\\\\  1 \\over 1 + e^{-z} } $$ can also be taken as (1- e * x)\n",
    "- Compare resulatant of ouput with Original value (given); if they are same, procedure can be stopped; if not we apply baclkward propation for updating weights\n",
    "- Backward Propagation : resumes where we left off, ie; backward (from right-to-left)\n",
    "    - New val of wi, $$ wi =  Old_Val_of_wi - [(eta_symbol) * derivative of { Error \\over old_Val_of_wi } ]$$\n",
    "    - ie; ivide, eta vechu all related weights for each output nokkanam/hidden layer \n",
    "        ie; differential of error for each dependant of Y<sub>i</sub> and/or H<sub>i</sub>\n",
    "     - (eta) is,  learning rate  ; decimals less than 1\n",
    "     - Chain rule of partial derivatives\n",
    "     * Str reaches left End of first cycle of this process : End of first iteration\n",
    "         1. Apply the same forward propagation;\n",
    "         2. Check values\n",
    "         3. If (!notEqual); \n",
    "            - Apply backward Propagation\n",
    "         4. Else \n",
    "             - Procedure terminates when it's done. \n",
    "- Gradient--- procedure => uses derivations/ differential calc\n",
    "- Gradient Descent\n",
    "    - Error is taken by mean_quare_error\n",
    "    - \n",
    "    - if this get's too complex, vanishing gradient will occur; procedures like LSDM is used\n",
    "- Manual process takes more than an 1hr\n",
    "- Steps :\n",
    "    1. Get Inputs X1, X2, X3 ...\n",
    "    2. Compute S, add bias to get Z\n",
    "    3. Apply activation with sigmoid fn; marks end of forward propagation; to get resultant output\n",
    "    4. Loop begins\n",
    "    5. Updation of Weights : Checking as mentioned above\n",
    "    - if found dissimilar; apply Backward Propagation until target value == output value\n",
    "    6. Terminate Process\n",
    "\n",
    "### Note : \n",
    "- RBM & Autoencoders\n",
    "- DNN is ANN with multiple hidden layers\n",
    "- CNN for image\n",
    "- RNN for sequential data\n",
    "\n",
    "    - Problems : Vanishing gradient, exploding gradient; Soln's like : LSDM\n",
    "    - LSDM, GRU, Gated RNN, Noturn encoders\n",
    "    \n",
    "- Multilayer Perceptron == Deep Feedforward network === feedforward neural network\n",
    "- z == linear regression; activation formular from logistical\n",
    "- ANN - speech recognition, anomaly detection, audio generation, spell check\n",
    "- Activation fn s :\n",
    " - Linear : fn is same as z\n",
    " - Step : if z less than 0, 0; greater than or equal to 0 ; is; like step fn in mathematics\n",
    " - Sigmpid : as above\n",
    " - Softmax : extension of sigmoid; e^x / summ of e^x; CNN; multiple inputs\n",
    " - ReLU : ; used for CNN\n",
    " - Hyperbolic : tanh\n",
    " $$ tanh = \\frac{\\\\ e^x - e^-x}{e^x + e^-x} $$\n",
    " - loss fn - cross entropy(classification), log loss, hinge loss, exponential loss, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9612e9-b004-43f7-9b6a-f1802569debd",
   "metadata": {},
   "source": [
    "### Practicals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21c994-84ba-4c3d-ad81-1384ce95e61a",
   "metadata": {},
   "source": [
    "#### Program 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512e35b1-abb8-4f1d-990b-fca81d7751f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67301742-2471-416d-90b5-7b970cddf52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sam = np.array([[1,0,1],[1,1,1],[0,1,0],[0,1,1]])\n",
    "out_sam = np.array([[1],[1],[0],[0]])\n",
    "in_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24671e75-2ac8-4552-b8de-9c1081543814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e119e1c9-480a-40f0-a415-68eab9f11736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77132064],\n",
       "       [0.02075195],\n",
       "       [0.63364823]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights\n",
    "#random.seed(); so that values remain same everytime we run\n",
    "np.random.seed(10)\n",
    "weights = np.random.random([3,1])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fec37975-cd5c-4e11-896d-500abf673d21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42496888],\n",
       "       [1.44572083],\n",
       "       [0.04075195],\n",
       "       [0.67440018]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = 0.02 \n",
    "sum = bias + np.dot(in_sam, weights)\n",
    "sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f20896ec-2794-4db6-aacd-efc95d7756b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8061162 ],\n",
       "       [0.80933899],\n",
       "       [0.51018658],\n",
       "       [0.66248773]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "pred_out = activation(sum)\n",
    "pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9aba205-c386-4ccc-8938-9821836ef940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1938838 ],\n",
       "       [ 0.19066101],\n",
       "       [-0.51018658],\n",
       "       [-0.66248773]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = out_sam - pred_out\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf6fdb-493c-4f9d-afb8-ca743f8449ac",
   "metadata": {},
   "source": [
    "when taking ; we must check whether matrix mult is possible or not #found by .shape\n",
    "and then perform adjustment #adjustment.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
