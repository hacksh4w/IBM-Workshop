{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa368d9-75a8-4b9f-96e7-56361b91faa6",
   "metadata": {},
   "source": [
    "### AI  > ML > Deep Learning > Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e63f11-c810-43d5-97f3-c4e0b8a7f786",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ANN\n",
    "## Str of Neural Network (ANN)\n",
    "### 3 Layers =>\n",
    "- Input Layer : Data inputed to NN; Each Circle represents one feature (a piece of info); Circles mean's variables / data set fed into it\n",
    "- Hidden layer 1 & 2 : processing\n",
    "- Output layer : Result\n",
    "* Perceptron : No Hidden layer; Direct from input to Output ; Linear classifier; has many limitations \n",
    " \n",
    "#### Comparison with Neuron :-\n",
    "* Dendrite : refers to input \n",
    "* Axon : output delivered thru axon\n",
    "    - width of dendrites define the weight associated with it\n",
    " \n",
    "### ANN\n",
    "- X1, X2 .... <= Input Layer\n",
    "- Y1, Y2, ... <= Output Layer\n",
    "-  S =  Î£ X<sub>i</sub> W<sub>i</sub>\n",
    "    - combinaions of X and W based on path for each prticular layer\n",
    "- Hidden Layer : H1, H2, ...\n",
    "- Wi <==> Weights  \n",
    "- Bias  : less than 1; B1, B2, ...\n",
    "- Activation with sigmoid fn => The output for a single layer (process of forward propagation)\n",
    "- Z ==> S + bias\n",
    "- Sigmoid Fn : $$ x = {\\\\  1 \\over 1 + e^{-z} } $$ can also be taken as (1- e * x)\n",
    "- Compare resulatant of ouput with Original value (given); if they are same, procedure can be stopped; if not we apply baclkward propation for updating weights\n",
    "- Backward Propagation : resumes where we left off, ie; backward (from right-to-left)\n",
    "    - New val of wi, $$ wi =  Old_Val_of_wi - [(eta_symbol) * derivative of { Error \\over old_Val_of_wi } ]$$\n",
    "    - ie; ivide, eta vechu all related weights for each output nokkanam/hidden layer \n",
    "        ie; differential of error for each dependant of Y<sub>i</sub> and/or H<sub>i</sub>\n",
    "     - (eta) is,  learning rate  ; decimals less than 1\n",
    "     - Chain rule of partial derivatives\n",
    "     * Str reaches left End of first cycle of this process : End of first iteration\n",
    "         1. Apply the same forward propagation;\n",
    "         2. Check values\n",
    "         3. If (!notEqual); \n",
    "            - Apply backward Propagation\n",
    "         4. Else \n",
    "             - Procedure terminates when it's done. \n",
    "- Gradient--- procedure => uses derivations/ differential calc\n",
    "- Gradient Descent\n",
    "    - Error is taken by mean_quare_error\n",
    "    - \n",
    "    - if this get's too complex, vanishing gradient will occur; procedures like LSDM is used\n",
    "- Manual process takes more than an 1hr\n",
    "- Steps :\n",
    "    1. Get Inputs X1, X2, X3 ...\n",
    "    2. Compute S, add bias to get Z\n",
    "    3. Apply activation with sigmoid fn; marks end of forward propagation; to get resultant output\n",
    "    4. Loop begins\n",
    "    5. Updation of Weights : Checking as mentioned above\n",
    "    - if found dissimilar; apply Backward Propagation until target value == output value\n",
    "    6. Terminate Process\n",
    "\n",
    "### Note : \n",
    "- When there is strict/necessary co-relation between data, it is called neural network\n",
    "- RBM & Autoencoders\n",
    "- overfitting & underfitting => L1, L2 regularization == penalty ii. dataset augmentation iii bagging & ensemble models iv early stopping ; adam optimiser\n",
    "- epochs entha? epochs kodukannam or itll run for a long time.\n",
    "- DNN is ANN with multiple hidden layers\n",
    "- CNN for image \n",
    "    - filters and kernels, convolution ; pooling\n",
    "- RNN for sequential data\n",
    "    - Problems : Vanishing gradient, exploding gradient; Soln's like : LSTM\n",
    "    - LSTM, GRU, Gated RNN, Noturn encoders\n",
    "- Multilayer Perceptron == Deep Feedforward network === feedforward neural network\n",
    "- z == linear regression; activation formular from logistical\n",
    "- ANN - speech recognition, anomaly detection, audio generation, spell check\n",
    "- Activation fn s : * can be applied on hidden layer\n",
    " - Linear : fn is same as z\n",
    " - Step : if z less than 0, 0; greater than or equal to 0 ; is; like step fn in mathematics\n",
    " - Sigmpid : as above\n",
    " - Softmax : extension of sigmoid; e^x / summ of e^x; CNN; multiple inputs\n",
    " - ReLU : ; used for CNN\n",
    " - Hyperbolic : tanh\n",
    " $$ tanh = \\frac{\\\\ e^x - e^-x}{e^x + e^-x} $$\n",
    " - loss fn - cross entropy(classification), log loss, hinge loss, exponential loss, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9612e9-b004-43f7-9b6a-f1802569debd",
   "metadata": {},
   "source": [
    "### Practicals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21c994-84ba-4c3d-ad81-1384ce95e61a",
   "metadata": {},
   "source": [
    "#### Program 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "512e35b1-abb8-4f1d-990b-fca81d7751f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "67301742-2471-416d-90b5-7b970cddf52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sam = np.array([[1,0,1],[1,1,1],[0,1,0],[0,1,1]])\n",
    "out_sam = np.array([[1],[1],[0],[0]])\n",
    "in_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "24671e75-2ac8-4552-b8de-9c1081543814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e119e1c9-480a-40f0-a415-68eab9f11736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77132064],\n",
       "       [0.02075195],\n",
       "       [0.63364823]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights\n",
    "#random.seed(); so that values remain same everytime we run\n",
    "np.random.seed(10)\n",
    "weights = np.random.random([3,1])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fec37975-cd5c-4e11-896d-500abf673d21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42496888],\n",
       "       [1.44572083],\n",
       "       [0.04075195],\n",
       "       [0.67440018]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = 0.02 \n",
    "sum = bias + np.dot(in_sam, weights)\n",
    "sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f20896ec-2794-4db6-aacd-efc95d7756b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8061162 ],\n",
       "       [0.80933899],\n",
       "       [0.51018658],\n",
       "       [0.66248773]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "pred_out = activation(sum)\n",
    "pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c9aba205-c386-4ccc-8938-9821836ef940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1938838 ],\n",
       "       [ 0.19066101],\n",
       "       [-0.51018658],\n",
       "       [-0.66248773]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = out_sam - pred_out\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf6fdb-493c-4f9d-afb8-ca743f8449ac",
   "metadata": {},
   "source": [
    "when taking ; we must check whether matrix mult is possible or not #found by .shape\n",
    "and then perform adjustment #adjustment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98067216-32a2-4879-b52c-6c5c587ff567",
   "metadata": {
    "tags": []
   },
   "source": [
    "kaggle mnist data set (structured & professional ) ; tf ; unstructured vechu padikka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "bbbd3827-94a3-44c7-bc27-880d19946b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'conda install theanos\\npip install keras \\n#restart kernel\\npip install tensorflow\\n# theano '"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''conda install theanos\n",
    "pip install keras \n",
    "#restart kernel\n",
    "pip install tensorflow\n",
    "# theano '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0136b7ff-d1ae-482e-9af4-da008062855c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "743b306d-cd5b-43d3-a472-3c87b1e1b5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "3b3c38e2-7aa4-450b-babb-faabd56fe4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(xtrain) = '"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as tf\n",
    "import matplotlib.pyplot as plt\n",
    "mnist  = tf.datasets.mnist\n",
    "'''(xtrain) = '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "92ca0968-0d7c-468c-a8d6-2a60ded91b42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#len(xtrain) # len od training sdataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "930805d4-2b50-4021-b285-291353e74937",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from keras.models import Sequential\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3bd89797-28c0-4d90-8ed3-75b2e0ec57f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CATEGORY\n",
       "e    152469\n",
       "b    115967\n",
       "t    108344\n",
       "m     45639\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('una.csv',usecols=['TITLE','CATEGORY'],on_bad_lines='skip')\n",
    "data.CATEGORY.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a4bacb80-f2dc-4235-90e0-059b90a11305",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_categories = 45000\n",
    "shuffled = data.reindex(np.random.permutation(data.index))\n",
    "e = shuffled[shuffled['CATEGORY']=='e'[:num_of_categories]]\n",
    "b = shuffled[shuffled['CATEGORY']=='b'[:num_of_categories]]\n",
    "t = shuffled[shuffled['CATEGORY']=='t'[:num_of_categories]]\n",
    "m = shuffled[shuffled['CATEGORY']=='m'[:num_of_categories]]\n",
    "concated = pd.concat([e,b,t,m],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "cf8b1a30-bf5d-40bc-9a6d-80b66bd66447",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffle the dataset\n",
    "concated = concated.reindex(np.random.permutation(concated.index))\n",
    "concated['LABEL']=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "02fa351f-86cb-4d86-8fd4-a1b946073eab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92153     0\n",
      "89855     0\n",
      "109502    0\n",
      "272462    2\n",
      "360158    2\n",
      "365118    2\n",
      "358861    2\n",
      "171018    1\n",
      "140668    0\n",
      "327934    2\n",
      "Name: LABEL, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Perform one-hot encoding on the labels data\n",
    "concated.loc[concated['CATEGORY']=='e','LABEL'] = 0\n",
    "concated.loc[concated['CATEGORY']=='b','LABEL'] = 1\n",
    "concated.loc[concated['CATEGORY']=='t','LABEL'] = 2\n",
    "concated.loc[concated['CATEGORY']=='m','LABEL'] = 3\n",
    "print(concated['LABEL'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ab04dc3c-2fb6-4b61-a0ec-0b255c942818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "labels = to_categorical(concated['LABEL'],num_classes=4)\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "ab806a2c-6ac2-40a5-84e9-d92356c67b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'CATEGORY' in concated.keys():\n",
    "    concated.drop(['CATEGORY'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d300d922-2cd0-4cbb-87d0-4087bd78acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform tokenization and identify the number of unique tokens\n",
    "n_most_common_words = 8000\n",
    "max_len = 130\n",
    "'''This class allows to vectorize a text corpus, by turning each text into\n",
    "either a sequence of integers (each integer being the index of a token in\n",
    "a dictionary) or into a vector '''\n",
    "tokenizer = Tokenizer(num_words=n_most_common_words,filters='!\"#$%&()*+,-./:;<+>?@[\\]^_`{|}~',lower=True)\n",
    "tokenizer.fit_on_texts(concated['TITLE'].values)\n",
    "sequences = tokenizer.texts_to_sequences(concated['TITLE'].values)\n",
    "word_index = tokenizer.word_index\n",
    "X = pad_sequences(sequences,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6d491c0e-8e83-47c3-9096-04bdd2bb6cee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Split the dataset into training and testing sets. Also, define epochs, batch size, and labels for the same\n",
    "X_train,X_test,y_train,y_test =train_test_split(X,labels,test_size=0.25,random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dd3f9c37-f8d8-4863-bdee-dcab2087d9a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=2\n",
    "emb_dim=128\n",
    "batch_size=256\n",
    "labels[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f4562d98-efff-41ca-ac17-9a2667a6771a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(316814, 130) (316814, 4) (105605, 130) (105605, 4)\n"
     ]
    }
   ],
   "source": [
    "#Code the LSTM model and fit the same into the processed data.\n",
    "print(X_train.shape,y_train.shape,X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d9174e06-0bda-4c3e-a03d-b6ba411a5973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Model.summary of <keras.engine.sequential.Sequential object at 0x00000255DDB05E10>>\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#Turns positive integers (indexes) into dense vectors of fixed size\n",
    "model.add(Embedding(n_most_common_words,emb_dim,input_length=X.shape[1]))\n",
    "#perform dropout\n",
    "model.add(SpatialDropout1D(0.7))\n",
    "#First LSTM layer with Dropout regularisation. To avoid overfitting\n",
    "model.add(LSTM(64,dropout=0.7,recurrent_dropout=0.7))\n",
    "#The output layer\n",
    "model.add(Dense(4,activation='softmax'))\n",
    "#perform optimization\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['acc'])\n",
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "980770fb-2e78-495a-aac4-6feffa53413d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "991/991 [==============================] - 917s 923ms/step - loss: 0.5058 - acc: 0.8046 - val_loss: 0.2343 - val_acc: 0.9197\n",
      "Epoch 2/2\n",
      "991/991 [==============================] - 992s 1s/step - loss: 0.2686 - acc: 0.9072 - val_loss: 0.2138 - val_acc: 0.9268\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train,y_train,epochs=epochs,batch_size=batch_size,validation_split=0.2,callbacks=[EarlyStopping(monitor='val_loss',min_delta=0,patience=0,verbose=0,mode=\"auto\",baseline=None,restore_best_weights=False,start_from_epoch=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae06c6e-22bd-4a8e-a42d-8f20754e2258",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the results on training and testing sets and obtain accuracy of the\n",
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n Loss:{:0.3f}\\n Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c8552-8b4f-436b-bedd-24806297e36d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Perform label predictions against random data.\n",
    "txt = [\"Stocks fall on weak china export data\"]\n",
    "seq = tokenizer.texts_to_sequences(txt)\n",
    "padded = pad_sequences(seq,maxlen=max_len)\n",
    "predict = model.predict(padded)\n",
    "labels = ['entertainment','business','science/tech','health']\n",
    "print(predict,labels[np.argmax(predict)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4548d9-1c8f-47f0-917b-41a78748bd09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
