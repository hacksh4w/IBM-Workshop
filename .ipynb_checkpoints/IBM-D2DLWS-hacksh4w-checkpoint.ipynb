{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aa368d9-75a8-4b9f-96e7-56361b91faa6",
   "metadata": {},
   "source": [
    "### AI  > ML > Deep Learning > Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e63f11-c810-43d5-97f3-c4e0b8a7f786",
   "metadata": {
    "tags": []
   },
   "source": [
    "# ANN\n",
    "## Str of Neural Network (ANN)\n",
    "### 3 Layers =>\n",
    "- Input Layer : Data inputed to NN; Each Circle represents one feature (a piece of info); Circles mean's variables / data set fed into it\n",
    "- Hidden layer 1 & 2 : processing\n",
    "- Output layer : Result\n",
    "* Perceptron : No Hidden layer; Direct from input to Output ; Linear classifier; has many limitations \n",
    " \n",
    "#### Comparison with Neuron :-\n",
    "* Dendrite : refers to input \n",
    "* Axon : output delivered thru axon\n",
    "    - width of dendrites define the weight associated with it\n",
    " \n",
    "### ANN\n",
    "- X1, X2 .... <= Input Layer\n",
    "- Y1, Y2, ... <= Output Layer\n",
    "-  S =  Î£ X<sub>i</sub> W<sub>i</sub>\n",
    "    - combinaions of X and W based on path for each prticular layer\n",
    "- Hidden Layer : H1, H2, ...\n",
    "- Wi <==> Weights  \n",
    "- Bias  : less than 1; B1, B2, ...\n",
    "- Activation with sigmoid fn => The output for a single layer (process of forward propagation)\n",
    "- Z ==> S + bias\n",
    "- Sigmoid Fn : $$ x = {\\\\  1 \\over 1 + e^{-z} } $$ can also be taken as (1- e * x)\n",
    "- Compare resulatant of ouput with Original value (given); if they are same, procedure can be stopped; if not we apply baclkward propation for updating weights\n",
    "- Backward Propagation : resumes where we left off, ie; backward (from right-to-left)\n",
    "    - New val of wi, $$ wi =  Old_Val_of_wi - [(eta_symbol) * derivative of { Error \\over old_Val_of_wi } ]$$\n",
    "    - ie; ivide, eta vechu all related weights for each output nokkanam/hidden layer \n",
    "        ie; differential of error for each dependant of Y<sub>i</sub> and/or H<sub>i</sub>\n",
    "     - (eta) is,  learning rate  ; decimals less than 1\n",
    "     - Chain rule of partial derivatives\n",
    "     * Str reaches left End of first cycle of this process : End of first iteration\n",
    "         1. Apply the same forward propagation;\n",
    "         2. Check values\n",
    "         3. If (!notEqual); \n",
    "            - Apply backward Propagation\n",
    "         4. Else \n",
    "             - Procedure terminates when it's done. \n",
    "- Gradient--- procedure => uses derivations/ differential calc\n",
    "- Gradient Descent\n",
    "    - Error is taken by mean_quare_error\n",
    "    - \n",
    "    - if this get's too complex, vanishing gradient will occur; procedures like LSDM is used\n",
    "- Manual process takes more than an 1hr\n",
    "- Steps :\n",
    "    1. Get Inputs X1, X2, X3 ...\n",
    "    2. Compute S, add bias to get Z\n",
    "    3. Apply activation with sigmoid fn; marks end of forward propagation; to get resultant output\n",
    "    4. Loop begins\n",
    "    5. Updation of Weights : Checking as mentioned above\n",
    "    - if found dissimilar; apply Backward Propagation until target value == output value\n",
    "    6. Terminate Process\n",
    "\n",
    "### Note : \n",
    "- When there is strict/necessary co-relation between data, it is called neural network\n",
    "- RBM & Autoencoders\n",
    "- overfitting & underfitting => L1, L2 regularization == penalty ii. dataset augmentation iii bagging & ensemble models iv early stopping ; adam optimiser\n",
    "- epochs entha? epochs kodukannam or itll run for a long time.\n",
    "- DNN is ANN with multiple hidden layers\n",
    "- CNN for image \n",
    "    - filters and kernels, convolution ; pooling\n",
    "- RNN for sequential data\n",
    "    - Problems : Vanishing gradient, exploding gradient; Soln's like : LSTM\n",
    "    - LSTM, GRU, Gated RNN, Noturn encoders\n",
    "- Multilayer Perceptron == Deep Feedforward network === feedforward neural network\n",
    "- z == linear regression; activation formular from logistical\n",
    "- ANN - speech recognition, anomaly detection, audio generation, spell check\n",
    "- Activation fn s : * can be applied on hidden layer\n",
    " - Linear : fn is same as z\n",
    " - Step : if z less than 0, 0; greater than or equal to 0 ; is; like step fn in mathematics\n",
    " - Sigmpid : as above\n",
    " - Softmax : extension of sigmoid; e^x / summ of e^x; CNN; multiple inputs\n",
    " - ReLU : ; used for CNN\n",
    " - Hyperbolic : tanh\n",
    " $$ tanh = \\frac{\\\\ e^x - e^-x}{e^x + e^-x} $$\n",
    " - loss fn - cross entropy(classification), log loss, hinge loss, exponential loss, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9612e9-b004-43f7-9b6a-f1802569debd",
   "metadata": {},
   "source": [
    "### Practicals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd21c994-84ba-4c3d-ad81-1384ce95e61a",
   "metadata": {},
   "source": [
    "#### Program 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "512e35b1-abb8-4f1d-990b-fca81d7751f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67301742-2471-416d-90b5-7b970cddf52d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [1, 1, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_sam = np.array([[1,0,1],[1,1,1],[0,1,0],[0,1,1]])\n",
    "out_sam = np.array([[1],[1],[0],[0]])\n",
    "in_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24671e75-2ac8-4552-b8de-9c1081543814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e119e1c9-480a-40f0-a415-68eab9f11736",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77132064],\n",
       "       [0.02075195],\n",
       "       [0.63364823]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights\n",
    "#random.seed(); so that values remain same everytime we run\n",
    "np.random.seed(10)\n",
    "weights = np.random.random([3,1])\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fec37975-cd5c-4e11-896d-500abf673d21",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.42496888],\n",
       "       [1.44572083],\n",
       "       [0.04075195],\n",
       "       [0.67440018]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias = 0.02 \n",
    "sum = bias + np.dot(in_sam, weights)\n",
    "sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f20896ec-2794-4db6-aacd-efc95d7756b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8061162 ],\n",
       "       [0.80933899],\n",
       "       [0.51018658],\n",
       "       [0.66248773]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def activation(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "pred_out = activation(sum)\n",
    "pred_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9aba205-c386-4ccc-8938-9821836ef940",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1938838 ],\n",
       "       [ 0.19066101],\n",
       "       [-0.51018658],\n",
       "       [-0.66248773]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error = out_sam - pred_out\n",
    "error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cf6fdb-493c-4f9d-afb8-ca743f8449ac",
   "metadata": {},
   "source": [
    "when taking ; we must check whether matrix mult is possible or not #found by .shape\n",
    "and then perform adjustment #adjustment.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98067216-32a2-4879-b52c-6c5c587ff567",
   "metadata": {
    "tags": []
   },
   "source": [
    "kaggle mnist data set (structured & professional ) ; tf ; unstructured vechu padikka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd3827-94a3-44c7-bc27-880d19946b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''conda install theanos\n",
    "pip install keras \n",
    "#restart kernel\n",
    "pip install tensorflow\n",
    "# theano '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0136b7ff-d1ae-482e-9af4-da008062855c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "743b306d-cd5b-43d3-a472-3c87b1e1b5e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b3c38e2-7aa4-450b-babb-faabd56fe4fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras as tf\n",
    "import matplotlib.pyplot as plt\n",
    "mnist  = tf.datasets.mnist\n",
    "(xtrain) = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92ca0968-0d7c-468c-a8d6-2a60ded91b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtrain' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mxtrain\u001b[49m) \u001b[38;5;66;03m# len od training sdataset \u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xtrain' is not defined"
     ]
    }
   ],
   "source": [
    "len(xtrain) # len od training sdataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930805d4-2b50-4021-b285-291353e74937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
